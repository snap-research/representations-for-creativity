
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>CVPR'21 Tutorial on Unlocking Creativity with Computer Vision: Representations for Animation, Stylization and Manipulation</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href="css/materialize.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />
</head>

<body id="page-top">
 <div class="navbar-fixed" >
    <nav class="teal lighten-2" role="navigation">
      <div class="nav-wrapper" >
        <ul class="center hide-on-med-and-down  nav navbar-nav navbar-center">
          <li><a class="page-scroll" href="#page-top" style="color:#CD853F;font-size:20px">Home</a></li>
          <li><a class="page-scroll" href="#overview" style="color:#CD853F;font-size:20px">Overview</a></li>
          <li><a class="page-scroll" href="#organizer" style="color:#CD853F;font-size:20px">Organizer</a></li>
          <li><a class="page-scroll" href="#schedule" style="color:#CD853F;font-size:20px">Schedule</a></li>
          <li><a class="page-scroll" href="#speaker" style="color:#CD853F;font-size:20px">Speaker</a></li>
        </ul>
      </div>
    </nav>
  </div>
<div class="container">
  <table border="0" align="center">
    <tr>
      <td width="700" align="center" valign="middle"><h3>CVPR 2021 Tutorial on</h3>
      <span class="title">Unlocking Creativity with Computer Vision: Representations for Animation, Stylization and Manipulation</span></td>
    </tr>
  </table>
        <h3 align="center">7:00~10:30 am (PDT), June 20, 2021</h3> 
        <h3 colspan="3" align="center"><br> Slides and recorded videos will be provided on this webpage.</h3>
<!--   <p><img src="figures/teaser.jpg" width="1000" align="middle" /></p> -->
</div>

</br>


<div class="container" id="overview">
  <h2>Overview</h2>
    <video controls poster="videos/thumbnail.png">
      <source src="videos/CVPR_2021_03.mp4" type="video/mp4">
    </video>
    <div class="overview">
    </br>
      <p>Creativity－the ability to create with the use of imagination and original ideas－requires a command of a diverse set of skills, availability of creative tools, a great deal of effort and most importantly a creative mind. Stylization or manipulation of an object requires an artist to understand the object's structure and factors of variation. Animation further requires the knowledge of rigid and non-rigid motion patterns of the object. Such complicated manipulations can be achieved by computer vision systems in which an appropriate representation is used.</p>

      <p>We will walk the attendee through designing and learning representations for building creative tools. Choosing the right representations and building a framework to learn it is often a key to unlocking the creativity. We will look at 2D and volumetric object representations, image and video representations, content, style and motion representations. Some representations can be learned in a supervised fashion, when labelled data is available, otherwise self-supervision can be adopted. Furthermore, we distinguish explicit explainable representations as well as implicit. We show that better representations lead to better understanding of the data, which in turn leads to higher quality of the generated content eventually forming a loop.</p>
    </div>
</div>

</br>



<div class="container" id="organizer">
  <h2>Organizers</h2>
    <div>

      <div class="instructor">
        <a href="http://www.stulyakov.com/">
            <div class="instructorphoto"><img src="figures/sergey.jpg"></div>
            <div>Sergey Tulyakov<br>Creative Vision, Snap Research<br><br></div>
        </a>
      </div>

      <div class="instructor">
        <a href="https://mlchai.com/">
            <div class="instructorphoto"><img src="figures/menglei.jpg"></div>
            <div>Menglei Chai<br>Creative Vision, Snap Research<br><br></div>
        </a>
      </div>

      <div class="instructor">
          <a href="https://research.snap.com/team/jian-ren/">
        <div class="instructorphoto"><img src="figures/jian.png"></div>
        <div>Jian Ren<br>Creative Vision, Snap Research<br><br></div>
        </a>
      </div>

      <div class="instructor">
        <a href="https://kyleolsz.github.io/">
            <div class="instructorphoto"><img src="figures/kyle.jpg"></div>
            <div>Kyle Olszewski<br>Creative Vision, Snap Research</div>
        </a>
      </div>

      <div class="instructor">
          <a href="http://vllab.ucmerced.edu/hylee/" >
        <div class="instructorphoto"><img src="figures/hsin.png"></div>
        <div>Hsin-Ying Lee<br>Creative Vision, Snap Research<br></div>
        </a>
      </div>

      <div class="instructor">
          <a href="https://zeng.science/">
        <div class="instructorphoto"><img src="figures/zeng.png"></div>
        <div>Zeng Huang<br>Creative Vision, Snap Research<br></div>
        </a>
      </div>
    </div>
    <p></p>
</div>

</br>


<div class="container" id="schedule">
  <h2>Tentative Schedule</h2>
    <div class="schedule">
      <p><span class="announce_date">30 mins</span>. <b>Preliminaries</b> <em>Stéphane Lathuilière</em></p>
      </br>
      <p style="font-size:20px"><b>Representations for controllable image and video synthesis</b></p>
      <p><span class="announce_date">15 mins</span>. <b>Image synthesis and manipulation</b> <em>Ming-Yu Liu</em></p>
      <p><span class="announce_date">15 mins</span>. <b>Video synthesis and manipulation</b> <em>Sergey Tulyakov</em></p>
      </br>
      <p  style="font-size:20px"><b>Object representations for manipulation</b></p>
      <p><span class="announce_date">15 mins</span>. <b>Manipulating hair</b> <em>Menglei Chai, Kyle Olszewski</em></p>
      <p><span class="announce_date">15 mins</span>. <b>Representations for modeling human bodies</b> <em>Zeng Huang, Kyle Olszewski</em></p>
      <p><span class="announce_date">15 mins</span>. <b>Volumetric implicit representations for object manipulation</b> <em>Kyle Olszewski</em></p>
      <p><span class="announce_date">15 mins</span>. <b>Manipulating objects via GAN-inversion</b> <em>Hsin-Ying Lee</em></p>
      </br>
      <p style="font-size:20px"><b>Content and motion representations for animation</b></p>
      <p><span class="announce_date">15 mins</span>. <b>Supervised and few-shot animation</b> <em>Jian Ren</em></p>
      <p><span class="announce_date">15 mins</span>. <b>Unsupervised animation of diverse objects</b> <em>Aliaksandr Siarohin, Sergey Tulyakov</em></p>
      </br>
      <p style="font-size:20px"><b>Representations for stylization</b></p>
      <p><span class="announce_date">15 mins</span>. <b>Appearance & geometry stylization for face image</b> <em>Menglei Chai</em></p>
      <p><span class="announce_date">15 mins</span>. <b>Interactive video stylization</b> <em>Menglei Chai</em></p>

    </div>
</div>

</br>

<div class="container" id='speaker'>
  <h2>About the speakers</h2>
    <div class="schedule">
        <p><b>Stéphane Lathuilière</b> is an associate professor (maître de conférence) at Telecom Paris, France, in the multimedia team. Until October 2019, he was a post-doctoral fellow at the University of Trento in the Multimedia and Human Understanding Group, led by Prof. Nicu Sebe and Prof. Elisa Ricci. He received the M.Sc. degree in applied mathematics and computer science from ENSIMAG, Grenoble Institute of Technology (Grenoble INP), France, in 2014. He completed his master thesis at the International Research Institute MICA (Hanoi, Vietnam). He worked towards his Ph.D. in mathematics and computer science in the Perception Team at Inria under the supervision of Dr. Radu Horaud, and obtained it from Université Grenoble Alpes (France) in 2018. His research interests cover machine learning for computer vision problems (eg. domain adaptation, continual learning) and deep models for image and video generation. He published papers in the most prestigious computer vision conferences (CVPR, ICCV, ECCV, NeurIPS) and top journals (T-PAMI).
</p>
        <p><b>Ming-Yu Liu</b> is a Distinguished Research Scientist and Manager at NVIDIA Research. Before joining NVIDIA in 2016, he was a Principal Research Scientist at Mitsubishi Electric Research Labs (MERL). He received his Ph.D. from the Department of Electrical and Computer Engineering at the University of Maryland College Park in 2012. Ming-Yu Liu has won several prestigious awards in his field. He is a recipient of the R&D 100 Award by R&D Magazine in 2014 for his robotic bin picking system. In SIGGRAPH 2019, he won the Best in Show Award and Audience Choice Award in the Real-Time Live track for his GauGAN work. His GauGAN work also won the Best of What's New Award by the Popular Science Magazine in 2019. His research interest is on generative image modeling. His goal is to enable machines' human-like imagination capability.
</p>
        <p><b>Sergey Tulyakov</b> is a Lead Research Scientist heading the Creative Vision team at Snap Research. His work focuses on creating methods for manipulating the world via computer vision and machine learning. This includes style transfer, photorealistic object manipulation and animation, video synthesis, prediction, retargeting. His work has been published as 20+ top papers and patents resulting in multiple innovative projects, including Snapchat Pet Tracking, OurBaby Snappable and Real-time Neural Lenses (gender swap, baby face, aging lens) and others. His work on Interactive Video Stylization received the Best in Show award at SIGGRAPH Real Time Live in 2020! Before joining Snap Inc., Sergey was with Carnegie Mellon University, Microsoft, NVIDIA. He holds a PhD degree from the University of Trento, Italy.
</p>
        <p><b>Menglei Chai</b>  is a Senior Research Scientist in the Creative Vision team at Snap Research. He received his Ph.D. degree from Zhejiang University in 2017, supervised by Professor Kun Zhou. He is doing research in the intersection between Computer Vision and Computer Graphics, majorly on human digitization, image manipulation, 3D reconstruction, and physics-based animation.
</p>
        <p><b>Kyle Olszewski</b> is a Research Scientist in the Creative Vision team at Snap Research. His research interests include real-time facial expression tracking for emerging domains such as AR/VR telepresence, intuitive interfaces for interactive photorealistic image synthesis, human body performance and appearance capture, and scene understanding for 3D reconstruction and image manipulation. He has published papers in venues such as Siggraph, Siggraph Asia, CVPR, ICCV and ECCV, and his work on Volumetric Human Teleportation was voted Best in Show at Siggraph 2020 Real-Time Live. He received his Ph.D. from the University of Southern California, at which he worked in the Geometric Capture Lab and Institute for Creative Technologies. Before joining Snap Research, he was a Senior Software Engineer at NVIDIA, and a research intern at Facebook/Oculus, Adobe, and Microsoft Research, and was a recipient of the 2018 Snap Research Fellowship.</p>
        <p><b>Zeng Huang</b>  is a Research Scientist in the Creative Vision team at Snap Research. His research efforts focus on 3D reconstruction and human digitizations specifically for consumer-level devices, allowing easy digital content creation for everyone. His work leverages a combination of computer graphics, vision, and machine learning. His work on real-time full body digitization has been awarded ‘Best in Show’ in Siggraph 2020 Real-Time Live!. He holds a Ph.D. degree from University of Southern California.
</p>
        <p><b>Hsin-Ying Lee</b>  is a Research Scientist in the Creative Vision team at Snap Research. He received his Ph.D degree from the University of California, Merced, in 2020. His work focuses on applying generative models to various content creation tasks, including image-to-image translation, dance modeling, design generation, and image editing. Before joining Snap Inc, Hsin-Ying was an intern at Google Research and Nvidia.
</p>
        <p><b>Jian Ren </b>  is a Research Scientist in the Creative Vision team at Snap Research. He got Ph.D. in Computer Engineering from Rutgers University in 2019. He is interested in image and video generation and manipulation, and efficient neural networks. Before joining Snap Inc, Jian did internships in Adobe, Snap, and Bytedance.</p>
        <p><b>Aliaksandr Siarohin</b>  received the M.Sc. degree in computer science from the University of Trento, Italy in 2017. He is currently a PhD student in the Multimedia and Human Understanding Group at the University of Trento. His primary research focus is domain adaptation, image and video generation and generative adversarial networks.
</p>

    </div>
</div>

</br>

<div class="containersmall">
    <p>Please contact <a href="stulyakov@snap.com">Sergey Tulyakov</a> if you have question. The webpage template is by the courtesy of awesome <a href="https://gkioxari.github.io/">Georgia</a>.</p>
</div>

<!--<p align="center" class="acknowledgement">Last updated: Jan. 6, 2017</p>-->
</body>
</html>
